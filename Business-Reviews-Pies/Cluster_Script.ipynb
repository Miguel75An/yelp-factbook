{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x922c9e8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile(\"yelp_business.csv\", use_unicode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['business_id,name,neighborhood,address,city,state,postal_code,latitude,longitude,stars,review_count,is_open,categories',\n",
       " 'FYWN1wneV18bWNgQjJ2GNg,\"\"\"Dental by Design\"\"\",,\"\"\"4855 E Warner Rd, Ste B9\"\"\",Ahwatukee,AZ,85044,33.3306902,-111.9785992,4.0,22,1,Dentists;General Dentistry;Health & Medical;Oral Surgeons;Cosmetic Dentists;Orthodontists']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174567\n",
      "+-----------+---------------------+------------------+\n",
      "|       City|Number_of_Restaurants|        Percentage|\n",
      "+-----------+---------------------+------------------+\n",
      "|  Las Vegas|                26775|15.337950471738646|\n",
      "|    Phoenix|                17213| 9.860397440524268|\n",
      "|    Toronto|                17206|  9.85638751883231|\n",
      "|  Charlotte|                 8553| 4.899551461616457|\n",
      "| Scottsdale|                 8228| 4.713376525918416|\n",
      "| Pittsburgh|                 6355|3.6404360503417026|\n",
      "|       Mesa|                 5760| 3.299592706525288|\n",
      "|  MontrÃ©al|                 5709|3.2703775627695957|\n",
      "|  Henderson|                 4465|2.5577571935130923|\n",
      "|      Tempe|                 4263|2.4420423104023095|\n",
      "|   Chandler|                 3994|2.2879467482399307|\n",
      "|  Edinburgh|                 3868|  2.21576815778469|\n",
      "|  Cleveland|                 3322|1.9029942658119807|\n",
      "|    Madison|                 3213|1.8405540566086374|\n",
      "|   Glendale|                 3206|1.8365441349166796|\n",
      "|    Gilbert|                 3128|1.7918621503491499|\n",
      "|Mississauga|                 2726| 1.561578076039572|\n",
      "|  Stuttgart|                 2000|1.1456919119879474|\n",
      "|     Peoria|                 1706|0.9772752009257192|\n",
      "|    Markham|                 1564|0.8959310751745749|\n",
      "+-----------+---------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "def extractCities(partId,records):\n",
    "    if partId==0:\n",
    "        records.next()\n",
    "    import csv\n",
    "    reader = csv.reader(records)\n",
    "    for row in reader:\n",
    "        yield (row[4]) #Cities #Put comma to explicity define a tuble of size one\n",
    "        \n",
    "cities = rdd.mapPartitionsWithIndex(extractCities)\n",
    "cities = cities.map(lambda city: (city,1)).reduceByKey(lambda x,y: x+y)\n",
    "cities = cities.toDF()\n",
    "\n",
    "#Rename\n",
    "cities = cities.select(cities['_1'].alias('City'),\n",
    "                       cities['_2'].alias('Number_of_Restaurants'))\n",
    "cities = cities.sort('Number_of_Restaurants',ascending = False)\n",
    "\n",
    "total = cities.select(\"Number_of_Restaurants\").agg({\"Number_of_Restaurants\": \"sum\"}).collect().pop()['sum(Number_of_Restaurants)']\n",
    "print(total)\n",
    "cities = cities.withColumn('Percentage', (cities['Number_of_Restaurants']/total) * 100)\n",
    "cities.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1094"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+\n",
      "|Stars|Number_of_Stars|\n",
      "+-----+---------------+\n",
      "|  4.0|          33492|\n",
      "|  3.5|          32038|\n",
      "|  5.0|          27540|\n",
      "|  4.5|          24796|\n",
      "|  3.0|          23142|\n",
      "|  2.5|          16148|\n",
      "|  2.0|           9320|\n",
      "|  1.5|           4303|\n",
      "|  1.0|           3788|\n",
      "+-----+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Percentage of bussiness with stars \n",
    "def extractStars(partId,records):\n",
    "    if partId==0:\n",
    "        records.next()\n",
    "    import csv\n",
    "    reader = csv.reader(records)\n",
    "    for row in reader:\n",
    "        yield (row[9]) #Cities #Put comma to explicity define a tuble of size one\n",
    "stars = rdd.mapPartitionsWithIndex(extractStars)\n",
    "stars = stars.map(lambda star: (star,1)).reduceByKey(lambda x,y: x+y)\n",
    "stars = stars.toDF()\n",
    "\n",
    "stars = stars.select(stars['_1'].alias('Stars'),\n",
    "                       stars['_2'].alias('Number_of_Stars'))\n",
    "stars = stars.sort('Number_of_Stars',ascending = False)\n",
    "stars.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviews and Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractRow(index, lines):\n",
    "    import csv\n",
    "    if index == 0:\n",
    "        lines.next()\n",
    "        \n",
    "    reader = csv.reader(lines)\n",
    "    for row in reader:\n",
    "        if len(row) == 9:\n",
    "            yield row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd = sc.textFile(\"yelp_review.csv\", use_unicode=False)\n",
    "rdd = rdd.mapPartitionsWithIndex(extractRow)\n",
    "rdd = rdd.map(lambda x: [x[0],x[1],x[2],x[3],x[4],x[5],x[6],x[7],x[8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2011-08-24', 979), ('2014-01-11', 1664)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates_rdd = rdd.map(lambda row: (row[4],1))\n",
    "\n",
    "from operator import add\n",
    "dates_rdd = dates_rdd.reduceByKey(add).cache()\n",
    "\n",
    "dates_rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2010-02-14', 379),\n",
       " ('2006-02-14', 9),\n",
       " ('2008-02-14', 84),\n",
       " ('2014-02-14', 1381),\n",
       " ('2007-02-14', 51),\n",
       " ('2013-02-14', 1147),\n",
       " ('2016-02-14', 3448),\n",
       " ('2015-02-14', 2346),\n",
       " ('2012-02-14', 883),\n",
       " ('2017-02-14', 2506),\n",
       " ('2011-02-14', 805),\n",
       " ('2009-02-14', 152)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FILTER VALENTINE DAYS ONLY\n",
    "\n",
    "valentines_dates = []\n",
    "for year in range(4,18):\n",
    "    valentines_dates.append('20' + (\"0\"+str(year) if year < 10 else str(year)) + '-02-14')\n",
    "    \n",
    "valentines_rdd = dates_rdd.filter(lambda row: row[0] in valentines_dates)\n",
    "valentines_rdd.take(12) #WORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2015-02-06', 1944),\n",
       " ('2017-02-28', 2876),\n",
       " ('2016-02-20', 3257),\n",
       " ('2015-02-07', 2307),\n",
       " ('2010-02-18', 427)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GET ALL REVIEWS IN FEBRUARY\n",
    "feb_days = []\n",
    "for year in range(4,18):\n",
    "    for day in range(1,30):\n",
    "        date = '20' + (\"0\"+str(year) if year < 10 else str(year)) + '-02-' + (\"0\"+str(day) if day < 10 else str(day))\n",
    "        feb_days.append(date)\n",
    "        \n",
    "feb_rdd = dates_rdd.filter(lambda row: row[0] in feb_days)\n",
    "feb_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2016-02-20', 3257),\n",
       " ('2016-02-27', 3121),\n",
       " ('2016-02-26', 2740),\n",
       " ('2016-02-25', 2705),\n",
       " ('2016-02-24', 2688),\n",
       " ('2016-02-29', 2959),\n",
       " ('2016-02-28', 3385),\n",
       " ('2016-02-18', 2797),\n",
       " ('2016-02-19', 2731),\n",
       " ('2016-02-12', 2619),\n",
       " ('2016-02-13', 3164),\n",
       " ('2016-02-10', 2681),\n",
       " ('2016-02-11', 2548),\n",
       " ('2016-02-16', 3155),\n",
       " ('2016-02-17', 2984),\n",
       " ('2016-02-14', 3448),\n",
       " ('2016-02-15', 3695),\n",
       " ('2016-02-09', 2490),\n",
       " ('2016-02-08', 2475),\n",
       " ('2016-02-01', 3037),\n",
       " ('2016-02-03', 2663),\n",
       " ('2016-02-02', 2577),\n",
       " ('2016-02-05', 2558),\n",
       " ('2016-02-23', 2705),\n",
       " ('2016-02-04', 2577),\n",
       " ('2016-02-22', 3180),\n",
       " ('2016-02-07', 3035),\n",
       " ('2016-02-21', 3450),\n",
       " ('2016-02-06', 3001)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show all reviews for year 2016 in February\n",
    "feb2016 = []\n",
    "for day in range(1,30):\n",
    "        date = '2016' + '-02-' + (\"0\"+str(day) if day < 10 else str(day))\n",
    "        feb2016.append(date)\n",
    "feb2016_rdd = feb_rdd.filter(lambda row: row[0] in feb2016)\n",
    "feb2016_rdd.take(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the schema necessary for the creation of a DataFrame\n",
    "from pyspark.sql.types import *\n",
    "schema = StructType([\n",
    "    StructField(\"Date\", StringType(), False), \n",
    "    StructField(\"Number_of_Reviews\", StringType(), False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|      Date|Number_of_Reviews|\n",
      "+----------+-----------------+\n",
      "|2016-02-20|             3257|\n",
      "|2016-02-27|             3121|\n",
      "+----------+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feb2016_df = sqlContext.createDataFrame(feb2016_rdd, schema)\n",
    "\n",
    "feb2016_df = feb2016_df.select(feb2016_df['Date'].cast(DateType()), \n",
    "                              feb2016_df['Number_of_Reviews'].cast(IntegerType())).cache()\n",
    "feb2016_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|      Date|Number_of_Reviews|\n",
      "+----------+-----------------+\n",
      "|2016-02-01|             3037|\n",
      "|2016-02-02|             2577|\n",
      "|2016-02-03|             2663|\n",
      "|2016-02-04|             2577|\n",
      "|2016-02-05|             2558|\n",
      "|2016-02-06|             3001|\n",
      "|2016-02-07|             3035|\n",
      "|2016-02-08|             2475|\n",
      "|2016-02-09|             2490|\n",
      "|2016-02-10|             2681|\n",
      "|2016-02-11|             2548|\n",
      "|2016-02-12|             2619|\n",
      "|2016-02-13|             3164|\n",
      "|2016-02-14|             3448|\n",
      "|2016-02-15|             3695|\n",
      "|2016-02-16|             3155|\n",
      "|2016-02-17|             2984|\n",
      "|2016-02-18|             2797|\n",
      "|2016-02-19|             2731|\n",
      "|2016-02-20|             3257|\n",
      "|2016-02-21|             3450|\n",
      "|2016-02-22|             3180|\n",
      "|2016-02-23|             2705|\n",
      "|2016-02-24|             2688|\n",
      "|2016-02-25|             2705|\n",
      "|2016-02-26|             2740|\n",
      "|2016-02-27|             3121|\n",
      "|2016-02-28|             3385|\n",
      "|2016-02-29|             2959|\n",
      "+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Sort february days\n",
    "feb2016_df = feb2016_df.orderBy('Date')\n",
    "feb2016_df.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SAVE IMAGES\n",
    "seriesToPlotDUAL = []\n",
    "year_pairs = []\n",
    "\n",
    "for i in range(6,17):\n",
    "    #for i in range(6,7):\n",
    "    year_pairs.append((i,i+1))\n",
    "    \n",
    "for year in year_pairs: \n",
    "    month_days = []\n",
    "    #DECEMBER\n",
    "    for day in range(1,32):\n",
    "        date = '20' + (\"0\"+str(year[0]) if year[0] < 10 else str(year[0])) +'-12-' + (\"0\"+str(day) if day < 10 else str(day))\n",
    "        month_days.append(date)\n",
    "        \n",
    "    #JANUARY    \n",
    "    for day in range(1,32):\n",
    "        date = '20' + (\"0\"+str(year[1]) if year[1] < 10 else str(year[1])) +'-01-' + (\"0\"+str(day) if day < 10 else str(day))\n",
    "        month_days.append(date)\n",
    "\n",
    "    #Get rdd\n",
    "    month_rdd = dates_rdd.filter(lambda row: row[0] in month_days)\n",
    "\n",
    "    #From dataframe\n",
    "    month_df = sqlContext.createDataFrame(month_rdd, schema)\n",
    "\n",
    "    month_df = month_df.select(month_df['Date'].cast(DateType()), \n",
    "                          month_df['Number_of_Reviews'].cast(IntegerType()))\n",
    "    month_df = month_df.orderBy('Date')\n",
    "\n",
    "    #Get days and reviews for those days\n",
    "    month_days = month_df.select(\"Date\").rdd.flatMap(lambda x: x).collect()\n",
    "#         for day in month_count:\n",
    "#             print(day)\n",
    "    month_days = map(lambda x: x.day,month_days)\n",
    "    \n",
    "    month_count = month_df.select(\"Number_of_Reviews\").rdd.flatMap(lambda x: x).collect()\n",
    "    month_x = range(1,63)\n",
    "    seriesToPlotDUAL.append((month_x,month_count,month_days))\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
